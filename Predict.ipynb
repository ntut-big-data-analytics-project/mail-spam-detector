{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation,Embedding,SimpleRNN,LSTM,GRU,CuDNNLSTM\n",
    "from keras.utils import to_categorical\n",
    "from gensim.models import word2vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import random\n",
    "from random import shuffle\n",
    "import os\n",
    "from glob import glob\n",
    "from zhconv import convert\n",
    "import email \n",
    "from email.header import decode_header\n",
    "import re\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('m.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = u\"([\\u4e00-\\u9fff]+)\"  \n",
    "\n",
    "\n",
    "\n",
    "str=open('asdf', 'r',encoding='utf8',errors='ignore').read()\n",
    "\n",
    "\n",
    "\n",
    "msg = email.message_from_string(str)\n",
    "subject, charset =decode_header(msg['SUBJECT'])[0]\n",
    "text=\"\"\n",
    "if charset:subject = subject.decode(charset,errors='ignore')\n",
    "pattern =   re.compile(xx)   \n",
    "subject =   pattern.findall(subject) \n",
    "print(subject)\n",
    "text=''.join(subject)\n",
    "print(text)\n",
    "charsetContent = msg.get_content_charset()\n",
    "\n",
    "if msg.get_content_type() == 'text/plain':\n",
    "    content = msg.get_payload(decode=True).decode(charsetContent).encode('utf8', 'replace')\n",
    "\n",
    "if msg.get_content_type() == 'text/html':\n",
    "    content = msg.get_payload(decode=True).decode(msg.get_content_charset())\n",
    "\n",
    "print(content)\n",
    "pattern =   re.compile(xx)  \n",
    "results =   pattern.findall(content)\n",
    "\n",
    "text=text.join(results)\n",
    "print(text)\n",
    "\n",
    "\n",
    "\n",
    "#print(HanziConv.toTraditional(str))\n",
    "seg_list = jieba.cut(convert(text, 'zh-cn'))\n",
    "\n",
    "\n",
    "\n",
    "with open('zxvc', \"w+\",encoding='utf8') as f:\n",
    "    f.write(\"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=[]\n",
    "k=''\n",
    "with open('zxvc','r',encoding='utf8') as f:\n",
    "    k=f.read().replace(\"\\n\",\"/\").replace(\" \",\"\").split(\"/\")\n",
    "while True:\n",
    "    k_index = k.index('') if '' in k else -1\n",
    "    if k_index==-1 :break\n",
    "    k.pop(k_index)\n",
    "print(k)\n",
    "s+=[k]\n",
    "\n",
    "templ=len(s)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(s))\n",
    "sequences = tokenizer.texts_to_sequences(s)\n",
    "data = pad_sequences(sequences,maxlen=200)\n",
    "print(sequences)\n",
    "print(data)\n",
    "\n",
    "y = model.predict_classes(data)\n",
    "\n",
    "\n",
    "\n",
    "print('spam' if(y[0]==0) else 'ham')\n",
    "#category={'spam': 0, 'ham': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
